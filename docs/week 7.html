<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>CASA0023 Learning Diary - 6&nbsp; Week 6 Classification I: Navigating Machine learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./week 8.html" rel="next">
<link href="./week 6.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./week 7.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Week 6 Classification I: Navigating Machine learning</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">CASA0023 Learning Diary</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Week 1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Week 1 Remote sensing: an Arial adventure</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week 2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Week 2 Xaringan: Crafting Stunning Presentations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week 3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Week 3 Correction: Refining the Lens</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week 4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Week 4 policy: Transformative Shifts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week 6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Week 5 GEE: Mapping the world</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week 7.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Week 6 Classification I: Navigating Machine learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week 8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">week 7 classification: Indepth</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week 9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">week 8 SAR: Reveling SAR</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#summary" id="toc-summary" class="nav-link active" data-scroll-target="#summary"><span class="header-section-number">6.1</span> summary</a></li>
  <li><a href="#application" id="toc-application" class="nav-link" data-scroll-target="#application"><span class="header-section-number">6.2</span> Application</a></li>
  <li><a href="#reflection" id="toc-reflection" class="nav-link" data-scroll-target="#reflection"><span class="header-section-number">6.3</span> Reflection</a></li>
  <li><a href="#reference" id="toc-reference" class="nav-link" data-scroll-target="#reference"><span class="header-section-number">6.4</span> Reference</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Week 6 Classification I: Navigating Machine learning</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="summary" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="summary"><span class="header-section-number">6.1</span> summary</h2>
<p>During the lecture, we were introduced to classification using remotely-sensed data, exploring various approaches to applying classification and different methods for analysis using machine learning tools like CART and Random Forest. We also reviewed several papers previously examined in the course, discussing the methodologies employed in these studies. Following that, we delved into applying these methods to our own research studies.</p>
<section id="cart" class="level4" data-number="6.1.0.1">
<h4 data-number="6.1.0.1" class="anchored" data-anchor-id="cart"><span class="header-section-number">6.1.0.1</span> <strong>CART</strong></h4>
<p>A binary decision classification tree method, simplifies decision-making through logical if-then scenarios. It recursively splits input data into groups based on predefined thresholds until reaching terminal nodes (Nods represent decision function ), with the most accurate tree selected. However, CART’s effectiveness can be limited by high dimensionality data.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/CART.gif" class="img-fluid figure-img" width="400"></p>
<figcaption class="figure-caption"><strong>Figure (1):</strong> CART source: Medium</figcaption>
</figure>
</div>
</section>
<section id="random-forest" class="level4" data-number="6.1.0.2">
<h4 data-number="6.1.0.2" class="anchored" data-anchor-id="random-forest"><span class="header-section-number">6.1.0.2</span> Random Forest</h4>
<p>An ensemble classifier that combines multiple CART trees. It generates decision trees using random selections of training datasets and variables, providing an unbiased assessment of generalization error. RF selects variables randomly at each node for tree building, with the optimal number of trees typically ranging from 100 to 500. The number of variables is determined by the square of the set of variables.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Random forest.gif" class="img-fluid figure-img" width="400"></p>
<figcaption class="figure-caption"><strong>Figure (2):</strong> Random Forest source: Medium</figcaption>
</figure>
</div>
</section>
<section id="support-vector-machinesvm" class="level4" data-number="6.1.0.3">
<h4 data-number="6.1.0.3" class="anchored" data-anchor-id="support-vector-machinesvm"><span class="header-section-number">6.1.0.3</span> Support Vector Machine(SVM)</h4>
<p>A supervised learning algorithm used for regression and classification problems. SVM constructs an ideal hyperplane during training to separate classes with the fewest misclassified pixels. It selects support vectors, extreme points that aid in hyperplane creation, using parameters like cost parameter C, Gamma, and kernel functions. Grid search is employed to define C and Gamma parameters, with C significantly influencing support vector selection and SVM performance. The linear kernel is preferred for training on large datasets.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Support Vector.gif" class="img-fluid figure-img" width="400"></p>
<figcaption class="figure-caption"><strong>Figure (3)</strong>: Support Vector Machine (SVM) source: Medium</figcaption>
</figure>
</div>
</section>
</section>
<section id="application" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="application"><span class="header-section-number">6.2</span> Application</h2>
<p>Machine learning is extensively employed across various domains including finance, trading technologies, healthcare, and traffic prediction. Exploring its application, particularly in image classification within remote sensing analysis using satellite images, is of great interest for me. Specifically focusing on urban environments, this section compares two studies: <u><strong><em>“Analysis of Land Use and Land Cover Using Machine Learning Algorithms on Google Earth Engine for Munneru River Basin, India”</em></strong></u> and <u><strong><em>“Mapping of Land Cover with Optical Images, Supervised Algorithms, and Google Earth Engine”.</em></strong></u> Both studies evaluate CART, Random Forest, and SVM algorithms for detecting land use and land cover (LULC) patterns.</p>
<p><u><strong>Analysis of Land Use and Land Cover Using Machine Learning Algorithms on Google Earth Engine for Munneru River Basin, India:</strong></u></p>
<p>This study aims to utilize machine learning algorithms on Google Earth Engine to classify land use and land cover (LULC) in the Munneru River Basin, India, comparing support vector machine (SVM), random forest (RF), and classification and regression trees (CART). Leveraging Earth observation data from Landsat-8 and Sentinel-2 satellite images, the analysis meticulously considers spatial resolutions and cloud cover criteria. Spectral bands from these satellites are used to classify LULC into five primary classes: water bodies, forests, barren lands, vegetation, and built-up areas. Orthorectified images with minimal cloud cover are processed using cloud mask algorithms, and yearly means of NDVI and NDWI indices are calculated to support classification. RF, CART, and SVM are then applied for comprehensive LULC analysis of the study area.</p>
<section id="method" class="level4" data-number="6.2.0.1">
<h4 data-number="6.2.0.1" class="anchored" data-anchor-id="method"><span class="header-section-number">6.2.0.1</span> <strong>Method</strong></h4>
<p>Orthorectified images with minimal cloud cover served as the primary input for classification. Cloud shadow and cover were removed using a cloud mask technique, followed by eliminating contaminated pixels. Yearly means of normalized difference vegetation index (NDVI) and normalized difference water index (NDWI) were computed. Landsat and Sentinel data were merged into composite images using the median filter. Training polygons were generated from high-resolution Google Earth images, evenly distributed across five land use classes. These polygons were loaded into Google Earth Engine (GEE) as a feature collection table. Machine learning algorithms such as Random Forest (RF), Classification and Regression Trees (CART), and Support Vector Machine (SVM) were trained using Landsat-8 and Sentinel-2 images to classify land use and land cover (LULC).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week 7 method.png" class="img-fluid figure-img" width="400"></p>
<figcaption class="figure-caption"><strong>Figure (4)</strong>: Methodology for LULC classification on the GEE platform.</figcaption>
</figure>
</div>
</section>
<section id="discussion" class="level4" data-number="6.2.0.2">
<h4 data-number="6.2.0.2" class="anchored" data-anchor-id="discussion"><span class="header-section-number">6.2.0.2</span> Discussion</h4>
<p>SVM, CART, and RF were employed to classify LULC using Landsat-8 and Sentinel-2 images on the GEE platform. Temporal aggregation methods were utilized to address gaps in cloudy images. NDWI and NDVI were utilized as additional inputs for LULC classification, representing water bodies and vegetation characteristics. A total of 575 training sites were utilized, with each class receiving 80-95 training samples and 65-80 validation samples. The best cross-validation factor for CART was determined to be 5 or 10. RF classification showed higher accuracy with a number of trees ranging from 50 to 100, with 100 trees yielding satisfactory results in this study. Important parameters such as kernel type, gamma value, and cost were considered in SVM classification. CART had a tendency to misclassify vegetation as built-up, water bodies, or forest in 2016 and 2018, and as barren land or water bodies in 202012. SVM slightly misclassified vegetation as forest, built-up, or water bodies in 2016 and as built-up or forest in 2018. However, SVM performed well in 2020, except for some forest and built-up areas. RF outperformed the other two classifiers in all three years.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week7 Discussion1.png" class="img-fluid figure-img" width="400"></p>
<figcaption class="figure-caption"><strong>Figure (5):</strong> LULC maps of Landsat-8 images using SVM, RF, and CART classifiers for the years 2016, 2018, and 2020.</figcaption>
</figure>
</div>
<p>In terms of accuracy, RF outperformed SVM and CART for both Landsat-8 and Sentinel-2 images7. The overall accuracy for Landsat-8 was 94.85% for RF, 90.88% for SVM, and 82.88% for CART. For Sentinel-2, the overall accuracy was 95.84% for RF, 93.65% for SVM, and 86.48% for CART. The kappa coefficients, which measure the agreement between predicted and observed categorizations, were also highest for RF.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week 7 accuracy .png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption"><strong>Figure (6):</strong> Kappa coefficient and overall accuracy of Landsat-8 and Sentinel-2 for various machine learning classifiers.</figcaption>
</figure>
</div>
<p><u><strong>Mapping of Land Cover with Optical Images, Supervised Algorithms, and Google Earth Engine:</strong></u></p>
<p>The objective of this study is to evaluate the effectiveness of optical satellite images for land and land-cover mapping. The study area, situated in the eastern region of Tabasco, Mexico, covers towns like Balancán, Emiliano Zapata, and Tenosique. Characterized by abundant aquifers and sediment accumulation from streams, rivers, and lagoons, the area experiences a hot-humid climate. Utilizing Sentinel-2 satellite imagery via Google Earth Engine, the study established two annual time series spanning 2017 to 2019, aligning with crop cycles and regional weather patterns. The methodology involved mapping crops and land use using spectral indices and machine learning algorithms (SVM, RF, CART). Detailed tables depict land-use coverage across three zones for various seasons, showcasing changes in cropland, shrubland, water bodies, and more. Comparative analysis of classification errors for corn and sorghum crops using SVM, RF, and CART was conducted.</p>
</section>
<section id="method-1" class="level4" data-number="6.2.0.3">
<h4 data-number="6.2.0.3" class="anchored" data-anchor-id="method-1"><span class="header-section-number">6.2.0.3</span> Method</h4>
<p>In the <strong>image selection phase</strong>, cloud masking using the QA60 band was employed to remove pixels with small accumulations of dense and cirrus clouds. A combination of reflectance thresholds and morphological operations was utilized to identify thick clouds and cirrus clouds, respectively. Then <strong>preprocessing phase</strong> involved calculating spectral indices for masked images, including NDVI, GNDVI, EVI, SAVI, and NDMI for vegetation detection, and NDWI for water bodies. Image correction techniques such as mosaicking and histogram reduction were applied to create mosaics of the study area, allowing for data aggregation over time. And <strong>the Supervised classification phase</strong> involved identifying main land types through visual analysis and applying RF, SVM, and CART algorithms to classify crops and soil types. Separate datasets were created for different crop cycles, and the dataset was divided into 70% for training and 30% for evaluation to avoid overtraining. SVM, RF, and CART algorithms were evaluated with different configurations to enhance classification efficiency.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week 7 method 2.png" class="img-fluid figure-img" width="400"></p>
<figcaption class="figure-caption"><strong>Figure (7):</strong> Proposed methodology for land-cover classification.</figcaption>
</figure>
</div>
</section>
<section id="discussion-1" class="level4" data-number="6.2.0.4">
<h4 data-number="6.2.0.4" class="anchored" data-anchor-id="discussion-1"><span class="header-section-number">6.2.0.4</span> Discussion</h4>
<p>The SVM, RF, and CART classification algorithms were evaluated using different configurations on the Google Earth Engine (GEE) platform to enhance classification efficiency. For SVM, a kernel with a radial and gamma base function of 0.7 was employed, along with a cost of 30. Training occurred during both spring–summer and autumn–winter seasons. RF was configured to limit random forest trees to 20, minimizing misclassifications. The base GEE configuration was used for CART due to its lower classification error rate.</p>
<p>Two primary categories were defined: (1) crop types (including corn and sorghum) and (2) land use types (such as water bodies, urban areas, and tropical rainforest). The study assessed the accuracy of these classifications using overall training accuracy (OA) and the kappa index (KI). SVM performed exceptionally well, achieving an OA and KI of 0.996% in both seasons. RF also showed strong performance, with an OA and KI greater than 0.990 in spring–summer and 0.96% and 0.95% in autumn–winter. CART achieved an OA of 0.94% and a KI of 0.92% in the first season and 0.98% and 0.97% in the second season.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week_7_accuracy_2.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption"><strong>Figure (8):</strong> Overall accuracy (OA) and Kappa index (KI) of the seasons.</figcaption>
</figure>
</div>
<p>Consider the limitations of data sources. The SIAP collects crop data based on planted hectares, ignoring crops that do not sprout or grow. Consequently, the margins of error between the algorithm-detected hectares and SIAP data are substantial. While SVM outperformed actual data, there may still be errors due to occasional cultivation of small or intermittent crop lands.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week_7_accuracy_3.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption"><strong>Figure (9):</strong> Percentage of corn and sorghum crop error by each classification method.</figcaption>
</figure>
</div>
</section>
<section id="conclusion" class="level4" data-number="6.2.0.5">
<h4 data-number="6.2.0.5" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">6.2.0.5</span> Conclusion</h4>
<p>The study methodology for land use and land cover (LULC) classification is outlined in both studiess, with the first one focusing on the preprocessing steps, feature selection, training dataset preparation, and classifier performance evaluation, particularly for SVM, CART, and RF classifiers. It provides detailed insights into the classification process, including input data selection, cloud masking techniques, temporal aggregation methods, and spectral index calculation. Moreover, it compares the classification results between the three classifiers, emphasizing the superior performance of RF over SVM and CART, this study presents accuracy assessment results using OA. The second study, meanwhile, discusses image selection, pre-processing, and supervised classification phases, detailing cloud masking, spectral index calculation, image correction, and classifier evaluation, with a focus on crop type classification. It also presents accuracy assessment results using OA and KI metrics. While both studies offer valuable insights, the first one provides a more comprehensive overview of the classification process and performance evaluation.</p>
</section>
</section>
<section id="reflection" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="reflection"><span class="header-section-number">6.3</span> Reflection</h2>
<p>In my journey of learning about machine learning applications in remote sensing, I initially found the concept quite hard. However, as I delved into research papers and explored the topic further, things started to fall into place. I was particularly intrigued to see how concepts we covered in lectures, like image correction and spectral index, were put into action combained with machine learning in real-world scenarios. For example, I learned about CART’s method of dividing data into groups based on predefined thresholds, which, although simple, is limited by high-dimensional data. On the other hand, RF, with its ensemble approach combining multiple CART trees, stood out for its ability to improve accuracy while reducing overfitting, although it requires more computational resources. SVM also caught my attention for its ability to create an optimal hyperplane for class separation with minimal misclassification, especially in datasets with many dimensions. However, I noted that it can be computationally intensive and sensitive to parameter tuning. Overall, I realized that choosing between these methods depends on various factors, such as the nature of the dataset, desired interpretability, available computational resources, and the trade-offs between accuracy and complexity.</p>
</section>
<section id="reference" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="reference"><span class="header-section-number">6.4</span> Reference</h2>
<p><strong>Analysis of Land Use and Land Cover Using Machine Learning Algorithms on Google Earth Engine for Munneru River Basin, India</strong> (Loukika K, Keesara V 2021).</p>
<p><strong>Mapping of Land Cover with Optical Images, Supervised Algorithms, and Google Earth Engine</strong> (Pech-May F, Aquino-Santos R 2022).</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./week 6.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Week 5 GEE: Mapping the world</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./week 8.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">week 7 classification: Indepth</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>